# Mental Health Checker - о чем и для кого проект?

Проект для людей, которые хотят своевременно оценить свой риск развития депрессии на основе личных данных.

Пользователь заполняет короткую форму о себе, а классические ML-модели (linear regression, random forest и XGBoost) предсказывают риск возникновения депрессии.  

# Архитектура

+ Клиентский слой — фронт (Streamlit-приложение) 

+ API слой (ml_service) — основной backend-сервис, реализованный на FastAPI. Обрабатывает HTTP-запросы, реализует бизнес-логику, взаимодействует с базой данных и кэшем, а также управляет задачами инференса

+ Слой ML-инференса (ml_inference) — отдельный микросервис, отвечающий за выполнение задач машинного обучения и предсказаний. Работает асинхронно и обрабатывает задачи из очереди

+ Инфраструктурные компоненты — базы данных, кэш, брокер сообщений и системы мониторинга

## Клиентский слой

С "честным" фронтом не заморачивалась, поэтому реализовала мордочку на **Streamlit** - быстро и просто. Легко разворачивается и минимально зависит от frontend-фреймворков.

## API слой

Основной backend-сервис, реализованный на FastAPI, отвечает за всю бизнес-логику и взаимодействие с внешними и внутренними компонентами.

+ Обрабатывает HTTP-запросы от клиентов (регистрация, аутентификация, баланс, история, запуск инференса).
+ Использует SQLAlchemy ORM для работы с базой данных PostgreSQL

+ Взаимодействует с Redis для кэширования данных (профилей пользователей, кредитов, истории задач), что снижает нагрузку на базу и ускоряет отклик
+ Реализует бизнес-логику 
+ Управляет постановкой задач инференса в очередь для ML-микросервиса

**Аутентификация и авторизация** - авторизация и аутентификация через JWT, а не куки, т.к. нужно простое и безопасное решение, не требующее доп.мер без-ти. Также используется FastAPI OAuth2PasswordRequestForm.

**Логирование событий и ошибок** с помощью собственного логгера.

**Интеграция с мониторингом** через Prometheus и визуализация с помощью Grafana.

## Слой ML-инференса

Отдельный микросервис, отвечающий за выполнение предсказаний.

+ Отдельный контейнер с Python-скриптами для загрузки моделей и масштабирования, предобработки данных и запуска предсказаний
+ Использует joblib для загрузки ML-моделей (pickle-файлы) и скейлера
+ Асинхронно обрабатывает задачи через `Celery`, которая получает задания из `Redis-брокера`
+ Логирует время выполнения и метрики инференса, отправляет их в `Prometheus`

## Инфра

Обеспечивающих стабильную и эффективную работу всего приложения:

+ `PostgreSQL` — реляционная бд для хранения пользователей, кредитов, задач инференса, истории транзакций.

+ `Redis` — высокопроизводительный in-memory кэш и брокер сообщений:

    + Кэширование часто используемых данных (профили, кредиты, история) для снижения нагрузки на базу.
    + Очередь задач Celery для асинхронного выполнения инференса.

+ `Celery` — система асинхронной обработки задач, взаимодействует с Redis как брокером.

+ `Prometheus` — система мониторинга метрик 

+ `Grafana` — визуализация метрик 

+ `Docker и docker-compose` — контейнеризация всех сервисов для удобного развертывания и масштабирования

### Метрики

Метрики мониторинга собираются и доступны в Grafana через Prometheus

**(кликните на гифку, чтобы воспроизвести)**

![Grafana Dashboard](assets/dashboard_show.gif)


Сейчас собираются метрики:
+ **API Health — Total HTTP Requests**. Позволяет мониторить активность сервиса, понять, какие маршруты наиболее загружены, и отследить тренды трафика
+ **95p Latency**. Позволяет выявить узкие места производительности и понять, как быстро API обрабатывает (почти) все запросы.
+ **Median Response Time**. Дополняет 95p, добавляет сведений о времени ожидании ответа
+ **FastAPI Errors**. Мониторит кол-во ошибок по эндпоинтам
+ **Avg Age**. Метрика по дате - средний возраст пользователей

### Тестирование

Постаралась покрыть тестами проект. Покрыты:

1) Бизнес-логика (unit-тесты сервисов ml_service/app/services)
2) API эндпоинты (интеграционные тесты FastAPI роутеров в ml_service/app/api)
3) ML-инференс (unit-тесты в ml_inference/model)
4) Асинхронная задача инференса (unit-тест ml_inference/tasks/run_inference.py)

Что можно сделать потом:

1) Тесты бд и миграций
2) Тесты кеширования Redis
3) Тесты на репо: проверить запросы и манипуляции с ORM 
4) Тесты безопасности: авторизация, защита эндпоинтов
5) Тесты фронта
6) Нагрузочное тестирование

# Структура проекта

```
# Структура проекта с пояснениями

mental_health_project
├─ .env                         # Файл с переменными окружения для настройки
├─ docker-compose.yml           # Конфигурация Docker Compose для всех сервисов
├─ logs                        # Логи работы разных компонентов системы
│  ├─ ml_inference_task.log    # Лог работы микросервиса ML инференса
│  ├─ model_loader.log         # Лог загрузки моделей
│  └─ predict.log              # Лог предсказаний
├─ ml_inference                # Микросервис для МЛ
│  ├─ core                    # Конфиги, логгирование, celery app
│  ├─ model                   # Логика загрузки и предсказания модели
│  ├─ models                  # Сохранённые обученные модели и скейлер
│  ├─ monitoring              # Метрики Prometheus для мониторинга(но пока не реализовано тут нормально)
│  ├─ tasks                   # Celery задача, запускающая предсказания
│  └─ requirements.txt        # зависимости микросервиса ML
├─ ml_service                 # Основной бэк
│  ├─ app
│  │  ├─ api                 # REST API роутеры (auth, billing, inference)
│  │  ├─ core                # Конфигурация, безопасность, логгирование
│  │  ├─ db                  # Модели, сессии и бд
│  │  ├─ repositories        # Слой доступа к данным 
│  │  ├─ schemas             # Pydantic-схемы 
│  │  ├─ services            # Бизнес-логика и сервисы (auth, billing, inference)
│  │  └─ monitoring          # Метрики для мониторинга API
|  |  |_ main.py             # точка входа 
│  ├─ Dockerfile             # докер-образ backend-сервиса
│  ├─ requirements.txt       # зависимости backend-сервиса
│  └─ init_db.py             # Скрипт инициализации базы данных
├─ shared                    # Общие схемы и модели, используемые в разных компонентах
├─ streamlit_front           # Клиентское приложение на Streamlit (фронт)
│  ├─ streamlit_app.py       # Основной UI и логика клиентского приложения
│  ├─ Dockerfile             # Образ frontend-приложения
│  └─ requirements.txt       # зависимости фронта
└─ tests                     # Тесты проекта
   ├─ ml_inference           # Тесты для микросервиса ML инференса
   └─ ml_service             # Тесты для backend-сервиса (API и сервисы)


```

# MVP

**(кликните на гифку, чтобы воспроизвести)**

![MVP](assets/mvp_show.gif)


# Рефлексия

+ самое главное - у меня нет прочного фундамента в виде предыдущего образования в сфере, поэтому пока дебаг иногда бывает тяжкий + частый вайбкодинг 
+ до clean архитектуры надо добивать - где-то еще остаются взаимовзависимости
+ для реального кейса нужно качать больше навыков - все-таки я не с sk learn моделями буду пилить следующие проекты
+ посредственно с celery разобралась
+ покрытие тестов до 100% добить
+ мониторинг сейчас очень базовый, даже недостаточный - смотрим только фастапи + 1 метрику по дате. по селери - ничего, других по дате тоже нет. 
+ фронт просто для вида, где-то дата в истории биллинга очень громоздкая, нужно поправить выводы

# Запуск проекта(локальный)

1. Проверьте, что **Docker** и **Docker Compose** установлены.

2. Клонируйте репозиторий:

   ```bash
   git clone https://github.com/neordic/mental_health_project.git

3. Перейдите в корневую папку проекта:

    ```bash
    cd mental_health_project

4. Запустите все сервисы:

    ```bash
    docker-compose up --build


